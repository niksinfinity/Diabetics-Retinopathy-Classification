
Diabetic RetinoPathy logstic regression Test One

```{r}
# Data is in arff type which is WEKA Software. USed Farrf lib for reading data

#Reading Data and Feature Naming
library(foreign)
library(car)
library(dplyr)
library(glmnet)

data<-read.arff("messidor_features.arff")

data<-data %>%
  mutate(DR = ifelse(data$Class == 1,1,0)) %>%
  select(-Class)

#View(data)
str(data)
#Base naming all features
colnames<-c(paste0("X",c(0:(ncol(data)-1))))
colnames
ncol(data)
names(data)<-colnames
data

#Naming Features X2-X7

feature.2.7<-c(paste0("X.MA",c(1:6)))
feature.2.7

#Naming Feature X8-X15
feature.8.15<-c(paste0("X.EX",c(1:8)))
feature.8.15

#Naming remaining all features

RFeatures<-c("Quality","Pre_Screening","EuclDist","DOpticDisc","AM_FM","DR")
#Combinig all features names
Features<-c(RFeatures[1:2],feature.2.7,feature.8.15,RFeatures[3:6])
names(data)<-Features
#View(data)
tdata<-data

#No NA's Found i.e missing data
tdata[is.na(tdata)]

v<-c(1,2,3,3,NA,2,1,NA,123)
v1<-c(1,2,3,3,2,1,123)
v[is.na(v)]
v1[is.na(v1)]
```



After performing somewhat data manpulation aka cleaning like feature naming,finding na's

Sampling Data into Train and Test as 70 to 30 ratio


```{r}
#Logistc Regression

#Sampling into Train and Test Data
set.seed(2)

s<-sample(1:nrow(tdata),0.7*nrow(tdata))
train<-tdata[s,]
test<-tdata[-s,]

#View(train)
#View(test)
```


VIF > 5 will be removed features


```{r}
#VIF

train.vif<-lm(DR ~. , data=train)
sort(vif(train.vif), decreasing = T)

#After removing X.MA2

train.vif<-lm(DR ~. -X.MA2,data=train)
sort(vif(train.vif), decreasing = T)

train.vif<-lm(DR ~. -X.MA2 -X.MA3,data=train)
sort(vif(train.vif), decreasing = T)

train.vif<-lm(DR ~. -X.MA2 -X.MA3 -X.MA4,data=train)
sort(vif(train.vif), decreasing = T)

train.vif<-lm(DR ~. -X.MA2 -X.MA3 -X.MA4 -X.MA5,data=train)
sort(vif(train.vif), decreasing = T)

train.vif<-lm(DR ~. -X.MA2 -X.MA3 -X.MA4 -X.MA5 - X.EX7,data=train)
sort(vif(train.vif), decreasing = T)

train.vif<-lm(DR ~. -X.MA2 -X.MA3 -X.MA4 -X.MA5 - X.EX7 -X.EX3,data=train)
sort(vif(train.vif), decreasing = T)

train.vif<-lm(DR ~. -X.MA2 -X.MA3 -X.MA4 -X.MA5 - X.EX7 -X.EX3 -X.EX5,data=train)
sort(vif(train.vif), decreasing = T)

#VIF with 5... are kept or else whole remaining parameters could be  useless

```

After Train Data VIF fit in glm left


```{r}

train
glm.train.fit<- train %>% select(-X.MA2,-X.MA3, -X.MA4, -X.MA5 ,- X.EX7, -X.EX3, -X.EX5)
glm.train.fit


fit = glm(DR ~.,family = "binomial", data = glm.train.fit)

fit<-step(fit)
formula(fit)

fit = glm(DR ~ Pre_Screening + X.MA1 + X.MA6 + X.EX1 + X.EX2 + 
    X.EX8 ,family = "binomial", data = glm.train.fit)
summary(fit)

```

```{r}

train$score <- predict(fit, newdata = train, type = "response")
library(ggplot2)
ggplot(train, aes(y=DR, x=score, color=factor(DR))) + geom_point() + geom_jitter()


```

```{r}
cutoff_data=data.frame(cutoff=0,TP=0,FP=0,FN=0,TN=0,P=0,N=0)
cutoffs=seq(0,1,length=100)

for (cutoff in cutoffs){
  predicted=as.numeric(train$score>cutoff)
  
  TP=sum(predicted==1 & train$DR==1)
  FP=sum(predicted==1 & train$DR==0)
  FN=sum(predicted==0 & train$DR==1)
  TN=sum(predicted==0 & train$DR==0)
  P=FN+TP
  N=TN+FP
  cutoff_data=rbind(cutoff_data,c(cutoff,TP,FP,FN,TN,P,N))
}

# removing the dummy data cotaining top row
cutoff_data=cutoff_data[-1,]


cutoff_data=cutoff_data %>%
  mutate(Sn=TP/P, Sp=TN/N,dist=sqrt((1-Sn)**2+(1-Sp)**2)) %>%
  mutate(KS=abs((TP/P)-(FP/N))) %>%
  mutate(Accuracy=(TP+TN)/(P+N)) %>%
  mutate(Lift=(TP/P)/((TP+FP)/(P+N))) %>%
  mutate(M=(8*FN+2*FP)/(P+N)) %>%
  select(-P,-N)
#P=FN+TP
 # N=TN+FP


#View(cutoff_data)

```

```{r}

library(tidyr)  
cutoff.viz = cutoff_data%>%
  select(cutoff,Sn,Sp,dist,KS,Accuracy,Lift,M)%>%
  gather(Criterion, value, Sn:M)
  
ggplot(filter(cutoff.viz,Criterion != "Lift"), aes(x=cutoff,y=value,color=Criterion))+geom_line()

test$score = predict(fit,newdata =test, type = "response")

KS.cutoff = cutoff_data$cutoff[which(cutoff_data$KS == max(cutoff_data$KS))][1]

table(y = train$DR,cutoff = as.numeric(train$score > KS.cutoff))

accuracy = (319+235)/(319+235+185+66)
accuracy*100

View(test)
```

